a Cox proportional hazards model/regression/multistage reg? (continuous-time survival) using lifelines, and/or a discrete-time logistic formulation (easy, often robust, uses standard sklearn tools).

1) Why this is a survival problem
You want to predict the time until the first positive return (e.g., first t where return > 0).

Some trades may never see a positive return within your observation window → right-censoring.

Survival models naturally handle differing follow-up times and censoring.

2) Modeling choices (short list + when to use)
A. Cox Proportional Hazards (CoxPH)
Semi-parametric; models hazard rate as h(t|x)=h0(t) * exp(Xβ).
Outputs relative risk; can compute survival curves and concordance (C-index).
Good baseline, interpretable coefficients.
Assumes proportional hazards (checkable).

B. Accelerated Failure Time (AFT)
Parametric alternative (Weibull, log-normal). Predicts multiplicative effect on time.
Useful if CoxPH assumptions fail.

C. Random Survival Forest (RSF) / Survival Gradient-boosting (e.g., scikit-survival, xgboost survival version, sksurv)
Nonlinear, handles interactions, robust to complex patterns and missingness (to some extent).
Good if Cox/AFT underfit.

D. Discrete-time survival via logistic regression (long-format)
Convert each row into multiple rows (one per time interval up to max horizon).
Fit a binary classifier for “event occurs at t” vs. not (conditional).
Works with standard sklearn models (logistic, xgboost).
Very flexible and simple to interpret; handles time-varying features easily.
	B — Discrete-time (long-format) logistic classifier (sklearn)
This converts each trade into up to max_horizon rows and trains a classifier that predicts event occurs at t (conditional on not happened before). Very flexible; you can use any classifier (logistic, xgboost).

E. Deep/Neural time-to-event (DeepSurv, deep Cox, seq models)
Powerful for very large datasets; more engineering needed.

3) How to define the event and censoring (concrete)
Event definition: First trading day t ≥ 1 such that ret_p_p{t}_td > 0 (positive arithmetic return relative to mebuy_price). You can also require a threshold, e.g. > 0.01 for +1%.

Time scale: trading days (1,2,3,...). Use discrete days since your price columns are discrete horizons.

Censoring: If no positive return up to your maximum horizon (e.g., 60 td), mark as censored at max_horizon.

Observation window: pick a reasonable max_horizon — maybe 60 or 120 td, but you already focused on ±20; choose what's meaningful for your application.

4) Key features to use
Numeric: qty, owned, value, insider_price, d_own_plus%_isnew, d_own_plus%, filing_price, mebuy_price

Historical (pre) prices: p_m1_td, p_m2_td, ... p_m20_td

Historical volumes: v_m1_td...v_m20_td

Derived features: backward returns (momentum), volatility over past windows, trade2file, ticker-level stats (avg vol, market cap if available), categorical encodings of trade_type, title.

Missingness indicators: binary flags for missing price/vol at each horizon (model can use these).

5) Evaluation metrics
Concordance index (C-index) — standard for survival models (higher = better).

Time-dependent AUC / ROC for specific horizons.

Brier score (proper scoring) and time-dependent Brier.

Calibration plots (predicted survival vs observed).

For discrete-time classifiers: precision/recall at given horizons, mean absolute error of predicted time (if you predict expected time).

6) Two starter implementations
Below are two runnable snippets. They assume you have computed ret_p_p{t}_td columns already and saved oip_mega_wreturns.csv. Adjust max_horizon as you like.